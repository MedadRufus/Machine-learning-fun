{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Analysing the Lending club data for fraud\n",
    "Specifically, this investigation is to find similar profiles of individuals who fraudulently make claims under different profiles in order to change their credit rating in order to get better interest rates etc.\n",
    "\n",
    "The idea for the investigation comes from this bloomberg article,\n",
    "https://www.bloomberg.com/news/features/2016-08-18/how-lending-club-s-biggest-fanboy-uncovered-shady-loans.\n",
    "Here an individual has found similar profiles rampant in the site and has led to considerable bad publicity for the service and has \"dethroned\" its CEO primarily because of his inaction and not revealing this matter to stakeholders.\n",
    "\n",
    "\n",
    "One unique aspect of this \"ebay for loans\" is that it publishes detailed information about its loans(abeit anonymised) and can be readily downloaded from the website. \n",
    "\n",
    "In this investigation I will use the capabilities of the scikit learn package to find similar profiles using the information given on the website as .csv files. The main tool I will use is the K nearest neighbour algorithms to look for similar profiles. Each feature such as the loan recepient's declared income,zip code,employment title and purpose for loan is considered as a dimension in the K nearest neighbour search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We now import the important packages\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use pandas to load the necessary columns in the csv file into memory. Note that there are several thousand entries and more than 100 columns so it is wise to selectively import the necessary columns to prevent memory overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"All raw data/LoanStats3d.csv\",skiprows=1,\n",
    "                 usecols=[\"home_ownership\",\"zip_code\",\"purpose\",\"emp_title\"\n",
    "                          ,\"emp_length\",\"annual_inc\",\"int_rate\",\"installment\",\n",
    "                          \"grade\",\"sub_grade\"],\n",
    "                 skipfooter=5,engine=\"python\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a brief look at a single column,\"home_ownership\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        RENT\n1        RENT\n2    MORTGAGE\n3    MORTGAGE\n4         OWN\nName: home_ownership, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"home_ownership\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the columns, \"emp_title\"(employment title) has a number of null values that causes type errors so I have replaced them with a string:\"not_revealed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emp_var = np.where(df[\"emp_title\"].isnull(), # Logical check\n",
    "                       \"not_revealed\",                       # Value if check is true\n",
    "                       df[\"emp_title\"])     # Value if check is false\n",
    "\n",
    "df[\"emp_title\"] = new_emp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now have to encode all the non numerical data such as zip code,house ownership status and employment title in a numerical format. Then it has to scaled to a standard scalar to prevent any bias towards any one particular feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize label encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3.6\\envs\\python35env\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3.6\\envs\\python35env\\lib\\site-packages\\ipykernel\\__main__.py:21: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "# Convert unordered variables to numeric and scale them to between 0 and 1\n",
    "\n",
    "encoded_home_ownership = label_encoder.fit_transform(df[\"home_ownership\"])\n",
    "ownership_minmax = min_max_scaler.fit_transform(encoded_home_ownership.reshape\n",
    "                                                (-1,1))\n",
    "\n",
    "encoded_zip = label_encoder.fit_transform(df[\"zip_code\"])\n",
    "zip_minmax = min_max_scaler.fit_transform(encoded_zip.reshape(-1,1))\n",
    "\n",
    "encoded_purpose = label_encoder.fit_transform(df[\"purpose\"])\n",
    "purpose_minmax = min_max_scaler.fit_transform(encoded_purpose.reshape\n",
    "                                                (-1,1))\n",
    "\n",
    "encoded_emp_title = label_encoder.fit_transform(df[\"emp_title\"])\n",
    "emp_title_minmax = min_max_scaler.fit_transform(encoded_emp_title.reshape\n",
    "                                                (-1,1))\n",
    "\n",
    "encoded_emp_length = label_encoder.fit_transform(df[\"emp_length\"])\n",
    "emp_length_minmax = min_max_scaler.fit_transform(encoded_emp_length.reshape\n",
    "                                                (-1,1))\n",
    "income_minmax = min_max_scaler.fit_transform(df[\"annual_inc\"].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at some of the standardised data from one column:\"loan purpose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15384615],\n       [ 0.07692308],\n       [ 0.15384615],\n       ..., \n       [ 0.30769231],\n       [ 0.15384615],\n       [ 0.15384615]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purpose_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we combine all the numpy arrays(feature data) into a pandas dataframe for simplicity sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ownership_minmax  zip_minmax  purpose_minmax  emp_title_minmax  \\\n0          1.000000    0.913472        0.153846          0.711243   \n1          1.000000    0.460022        0.076923          0.624844   \n2          0.333333    0.944140        0.153846          0.615573   \n3          0.333333    0.709748        0.076923          0.778456   \n4          0.666667    0.236583        0.153846          0.778456   \n\n   emp_length_minmax  income_minmax  \n0           0.636364       0.015789  \n1           0.909091       0.005474  \n2           0.818182       0.014947  \n3           0.545455       0.005053  \n4           0.090909       0.007163  \n"
     ]
    }
   ],
   "source": [
    "data = np.hstack([ownership_minmax,zip_minmax,purpose_minmax,emp_title_minmax,\n",
    "                 emp_length_minmax,income_minmax])\n",
    "\n",
    "data_features = pd.DataFrame(data,\n",
    "                             columns=[\"ownership_minmax\",\"zip_minmax\",\n",
    "                                      \"purpose_minmax\",\"emp_title_minmax\",\n",
    "                 \"emp_length_minmax\",\"income_minmax\"])\n",
    "\n",
    "\n",
    "print(data_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load all the data into memory and index it using the inbuilt nearest neighbours algorithm in scikit-learn. The algorithm used here is the ball tree algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now query the ball tree with individual profiles and find the most similar profile in the huge ball tree. The metric for closest neighbour is the eucledian distance. The query will return the distance to the nearest profile and the index of that profile in the profile population.We willthen manually have a look at the similar profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: [  2.05263158e-05]\n\nsimilar profile 1:\nint_rate                       7.26%\ninstallment                   774.91\ngrade                              A\nsub_grade                         A4\nemp_title                    Manager\nemp_length                 10+ years\nhome_ownership                  RENT\nannual_inc                    102000\npurpose           debt_consolidation\nzip_code                       937xx\nName: 198880, dtype: object\n\nsimilar profile 2:\nint_rate                      17.57%\ninstallment                   704.49\ngrade                              D\nsub_grade                         D4\nemp_title                    Manager\nemp_length                 10+ years\nhome_ownership                  RENT\nannual_inc                    102195\npurpose           debt_consolidation\nzip_code                       937xx\nName: 35836, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#index number 1003 seems to be very interesting. a look into that is recommmended\n",
    "#here we select the range of profiles to query into the tree. Here we have queried betwen profile 35000 and 37000\n",
    "query = data_features.iloc[35000:37000]\n",
    "distances, indices = nbrs.kneighbors(query)\n",
    "\n",
    "#logic to deter mine the closest profiles by distance and find those indexes to recover the original profile data\n",
    "abs_distances = distances[:, 1]\n",
    "min_distance = abs_distances[(abs_distances > 0)].min()\n",
    "min_loc = np.where((distances == min_distance))\n",
    "\n",
    "#now display all the similar profiles\n",
    "print(\"distance:\", distances[min_loc])\n",
    "print(\"\")\n",
    "\n",
    "print(\"similar profile 1:\")\n",
    "print(df.iloc[indices[min_loc[0]][0][1]])\n",
    "print(\"\")\n",
    "\n",
    "print(\"similar profile 2:\")\n",
    "print(df.iloc[indices[min_loc[0]][0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might see, the two profiles shown above are very similar. This profile can manually be investigated if needed by the bank or firm. As seen from the above example, the individual has furnished slightly different information but has a widely difffering credit rating(A4 and D4). Investers are likely to be misled by this false information. As seen here the two loans have widely differing interest rates for the same person(and credit worthiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar profile pairs:333083,1180"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
